# AQM Server Database — Implementation Roadmap

## Timeline: 2 Sprints (~4 weeks)

---

## Sprint 1 (Weeks 1–2): Core Database + Delete-on-Fetch

### Week 1: Foundation

| Day | Task | Exit Criteria |
|-----|------|---------------|
| 1 | Docker Compose: add PostgreSQL 16 alongside existing Redis. Connect via `psql` CLI. | `\conninfo` shows connected to `aqm` database |
| 2 | Write `migrations/001_create_coin_inventory.sql` — table + all 3 indexes + schema_version table. Run it. | `\d coin_inventory` shows correct schema, `\di` shows 3 indexes |
| 3 | `db.py` — `create_pool()`, `close_pool()`, `health_check()`. Write test. | Pool creates, health check passes, pool closes cleanly |
| 4 | `coin_inventory.py` — `upload_coins()` with `executemany` + `ON CONFLICT DO NOTHING`. Write tests. | Upload 10 coins → 10 rows. Upload same 10 again → still 10 rows. |
| 5 | `coin_inventory.py` — `get_inventory_count()`. Write test. | Upload mixed tiers → counts match per category |

### Week 2: Delete-on-Fetch + Maintenance

| Day | Task | Exit Criteria |
|-----|------|---------------|
| 1 | `coin_inventory.py` — `fetch_coins()` CTE with `FOR UPDATE SKIP LOCKED`. | Upload 5, fetch 3 → 3 returned, 2 still available |
| 2 | Concurrency stress test: 20 async tasks fetching 1 key each from same user. | Set of returned key_ids has exactly 20 unique entries. Zero duplicates. |
| 3 | Edge cases: fetch more than available, fetch from empty user, fetch wrong tier. | Partial results returned gracefully, no errors on empty |
| 4 | `purge_stale()` + `hard_delete_fetched()`. Write tests. | Old unfetched → purged. Old fetched → hard deleted. Recent → untouched. |
| 5 | Full cycle integration test: upload → fetch → verify claimed → purge stale → hard delete. | All 5 operations work in sequence, counts correct at each step |

### Sprint 1 Deliverables
- [ ] PostgreSQL running in Docker with schema applied
- [ ] `db.py` — pool management (3 functions)
- [ ] `coin_inventory.py` — all 5 core operations
- [ ] Zero-duplicate proof under concurrency
- [ ] ~15 tests passing

---

## Sprint 2 (Weeks 3–4): API Layer + Production Hardening

### Week 3: FastAPI Endpoints

| Day | Task | Exit Criteria |
|-----|------|---------------|
| 1 | `types.py` + `errors.py` — server-specific types and exceptions | Clean imports, no circular deps |
| 2 | `api.py` — `POST /v1/coins/upload` with base64 decode, input validation, size limits | TestClient: valid upload → 200, invalid category → 422, oversized blob → 413 |
| 3 | `api.py` — `GET /v1/coins/fetch` with query params | TestClient: fetch → coins returned with b64 encoded blobs |
| 4 | `api.py` — `GET /v1/coins/count` + `GET /v1/health` | TestClient: count matches, health returns db status |
| 5 | `api.py` — admin endpoints: `POST /v1/admin/purge-stale`, `POST /v1/admin/hard-delete` | TestClient: purge returns deleted count |

### Week 4: Hardening + Load Testing

| Day | Task | Exit Criteria |
|-----|------|---------------|
| 1 | `scheduler.py` — APScheduler wiring: purge daily, hard-delete hourly | Scheduler runs, logs results |
| 2 | Connection pool tuning: timeouts, max connections, idle cleanup. Add `config.py`. | Pool handles 50 concurrent connections without exhaustion |
| 3 | Load test: 10K concurrent fetch requests via `asyncio.gather`. Measure p50/p95/p99 latency. | p99 < 50ms for fetch_coins |
| 4 | Add rate limiting to API (per-user). Add request logging. | No single user can exhaust server with rapid requests |
| 5 | Documentation: API spec (OpenAPI auto-generated by FastAPI), deployment notes, monitoring queries | Swagger UI at `/docs` works, runbook complete |

### Sprint 2 Deliverables
- [ ] FastAPI app with 5 endpoints + auto-generated OpenAPI docs
- [ ] Input validation on all endpoints
- [ ] Background scheduler for maintenance jobs
- [ ] Load test results: p99 latency documented
- [ ] Rate limiting + request logging
- [ ] ~25 total tests passing

---

## Dependency Install

Add to your existing `environment.yml`:

```yaml
  - asyncpg
  - fastapi
  - uvicorn
  - httpx          # for API testing
  - apscheduler    # for background jobs
```

Or pip:
```bash
pip install asyncpg fastapi uvicorn httpx apscheduler --break-system-packages
```

---

## Quick Reference: What Goes Where

| Function | File | Depends On |
|----------|------|------------|
| `create_pool()` | `db.py` | asyncpg |
| `close_pool()` | `db.py` | asyncpg |
| `health_check()` | `db.py` | asyncpg |
| `upload_coins()` | `coin_inventory.py` | db.py pool |
| `fetch_coins()` | `coin_inventory.py` | db.py pool |
| `get_inventory_count()` | `coin_inventory.py` | db.py pool |
| `purge_stale()` | `coin_inventory.py` | db.py pool |
| `hard_delete_fetched()` | `coin_inventory.py` | db.py pool |
| `POST /v1/coins/upload` | `api.py` | coin_inventory |
| `GET /v1/coins/fetch` | `api.py` | coin_inventory |
| `GET /v1/coins/count` | `api.py` | coin_inventory |
| `GET /v1/health` | `api.py` | db.py |
| `POST /v1/admin/purge-stale` | `api.py` | coin_inventory |
| `POST /v1/admin/hard-delete` | `api.py` | coin_inventory |
| purge scheduler | `scheduler.py` | coin_inventory |
| hard-delete scheduler | `scheduler.py` | coin_inventory |
